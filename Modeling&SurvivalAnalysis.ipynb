{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_columns',1000)\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import decomposition\n",
    "from sklearn.metrics import average_precision_score\n",
    "import pickle\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "import datetime\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression,Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import make_scorer\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from local directory, remember to change the directory\n",
    "listing = pd.read_csv('roofstock_marketplace_listing_historical_full.csv')\n",
    "transaction = pd.read_csv('roofstock_marketplace_transactions_full.csv')\n",
    "offer = pd.read_csv('roofstock_marketplace_offers_full.csv')\n",
    "buyer = pd.read_csv('roofstock_marketplace_buyers_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "newdf=pd.read_csv('without_estimate.csv')\n",
    "newdf['DISCOUNT']=newdf['OFFER_PRICE']/newdf['LIST_PRICE']\n",
    "zesti=pd.read_csv('zestimate_data.csv')\n",
    "zesti_dic=zesti.set_index('LISTING_ID')['zestimate'].to_dict()\n",
    "newdf['ZESTIMATE']=newdf['LISTING_ID'].map(lambda x: zesti_dic[x])\n",
    "#newdf['ZESTIMATE_DISCOUNT']=newdf['LIST_PRICE']/newdf['ZESTIMATE']\n",
    "newdf['ZESTIMATE_DIFFERENCE']=newdf['LIST_PRICE']-newdf['ZESTIMATE']\n",
    "\n",
    "newdf['OFFER_OR_NOT']=newdf['diff_days'].map(lambda x: 1 if x<180 else 0)\n",
    "newdf['OFFER_OR_NOT']=newdf['OFFER_OR_NOT'].astype('category')\n",
    "INSPECTION_TYPE_ID=pd.get_dummies(newdf['INSPECTION_TYPE_ID'],dummy_na=True,prefix='INSPECTION_TYPE_ID')\n",
    "newdf=pd.concat([newdf,INSPECTION_TYPE_ID],axis=1)\n",
    "newdf=newdf.drop('INSPECTION_TYPE_ID',axis=1)\n",
    "\n",
    "ddrop=[]\n",
    "for i in newdf.columns:\n",
    "    if 'LEASING' in i:\n",
    "        ddrop.append(i)\n",
    "\n",
    "for i in newdf.columns:\n",
    "    if 'PAYMENTSTATUS' in i:\n",
    "        ddrop.append(i)\n",
    "\n",
    "newdf=newdf.drop(ddrop,axis=1)\n",
    "newdf=newdf.drop(['GMAPPOVHEADING','GMAPPOVPITCH','ISALLOWOFFER','PRICEVISIBILITY','HASAUDIO','ISEXCLUSIVE'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_has_offer=newdf[newdf['diff_days']<=180]\n",
    "df_has_offer=df_has_offer[df_has_offer['LISTING_STATUS_For Sale']==1]\n",
    "ddrop1=[]\n",
    "for i in newdf.columns:\n",
    "    if 'LISTING_STATUS' in i:\n",
    "        ddrop1.append(i)\n",
    "df_has_offer=df_has_offer.drop(ddrop1[1:],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_has_offer=df_has_offer.groupby('LISTING_ID').apply(lambda t: t[t.EVENT_UTC==t.EVENT_UTC.min()]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_has_offer=df_has_offer.drop_duplicates(subset=['LISTING_ID','EVENT_UTC'],keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_has_offer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_has_offer=df_has_offer.drop('LISTING_ID',axis=1).reset_index().drop('level_1',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_has_offer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Survival analysis\n",
    "listing['REC_END_TS']=listing['REC_END_TS'].map(lambda x: x[:10])\n",
    "listing=listing[listing['LIST_PRICE'].isnull()==False]\n",
    "df_list=[]\n",
    "for i in tqdm(df_has_offer.index):\n",
    "    try:\n",
    "        offer_date=df_has_offer['EVENT_UTC'][i][:10]\n",
    "        initial_publish_date=df_has_offer['LISTING_INITIAL_PUBLISH_TS'][i][:10]\n",
    "        listing_id=df_has_offer['LISTING_ID'][i]\n",
    "        listing1=listing[(listing['LISTING_ID']==listing_id)&(listing['REC_END_TS']<=offer_date)&(listing['REC_END_TS']>=initial_publish_date)]\n",
    "        listing1['REC_END_TS']=listing1['REC_END_TS'].map(lambda x:x[:10])\n",
    "        xx=listing1[['LISTING_ID','REC_END_TS','LISTING_INITIAL_PUBLISH_TS','LIST_PRICE']].sort_values('REC_END_TS').drop_duplicates(subset=['REC_END_TS'],keep='first')\n",
    "        xx1=xx.reset_index()\n",
    "        initial_list_price=xx1['LIST_PRICE'][0]\n",
    "        xx=xx.dropna(subset=['LISTING_INITIAL_PUBLISH_TS'])\n",
    "        xx['LISTING_INITIAL_PUBLISH_TS']=xx['LISTING_INITIAL_PUBLISH_TS'].map(lambda x:x[:10])\n",
    "        xx['REC_END_TS']=pd.to_datetime(xx['REC_END_TS'])\n",
    "        xx['LISTING_INITIAL_PUBLISH_TS']=pd.to_datetime(xx['LISTING_INITIAL_PUBLISH_TS'])\n",
    "        xx['DAYS_ON_MARKET']=xx['REC_END_TS']-xx['LISTING_INITIAL_PUBLISH_TS']\n",
    "        xx['DAYS_ON_MARKET']=xx['DAYS_ON_MARKET'].map(lambda x: x.days)\n",
    "        diff_days=max(2,(df_has_offer.iloc[i:i+1,]['diff_days'][i]))\n",
    "        s_df=pd.concat([(df_has_offer.iloc[i:i+1,])]*int(diff_days-1))\n",
    "        s_df=s_df.reset_index().drop('index',axis=1)\n",
    "        s_df['DAY_ON_MARKET']=list(range(int(diff_days-1)))\n",
    "        s_df['INITIAL_LIST_PRICE']=initial_list_price\n",
    "        today_price_list=[]\n",
    "        for x in s_df.index:\n",
    "            try:\n",
    "                mm=xx[xx['DAYS_ON_MARKET']<=s_df['DAY_ON_MARKET'][x]]\n",
    "                today_price_list.append(mm[mm['DAYS_ON_MARKET']==mm['DAYS_ON_MARKET'].max()]['LIST_PRICE'].iloc[0,])\n",
    "            except:\n",
    "                today_price_list.append(initial_list_price)\n",
    "        s_df['CURRENT_LIST_PRICE']=today_price_list\n",
    "        s_df['OFFER_TOMORROW']=0\n",
    "        s_df=s_df.set_value(s_df.index[-1],'OFFER_TOMORROW',1)\n",
    "        df_list.append(s_df)\n",
    "    except:\n",
    "        print(i)\n",
    "df_survival=pd.concat(df_list)\n",
    "df_survival=df_survival.reset_index().drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_list=[]\n",
    "for i in tqdm(df_survival['LISTING_ID'].unique()):\n",
    "    aa=df_survival[df_survival['LISTING_ID']==i]\n",
    "    bb=aa.tail(1)\n",
    "    cc=bb.copy()\n",
    "    cc['OFFER_TOMORROW']=0\n",
    "    dd_list.append(pd.concat([aa]+[cc]*(179-len(aa))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_survival2=pd.concat(dd_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_id=random.sample(list(df_survival['LISTING_ID'].unique()),int(len(list(df_survival['LISTING_ID'].unique()))*0.6))\n",
    "test_id=list(set(df_survival['LISTING_ID'].unique())-set(train_id))\n",
    "df_survival1=df_survival2.drop(['EVENT_UTC','OFFER_OR_NOT',\n",
    "                                                                 'LISTING_INITIAL_PUBLISH_TS','DISCOUNT','OFFER_OR_NOT','ZESTIMATE',\n",
    "                                                                 'PREVIOUSYEARLYPROPERTYTAXES'],axis=1)  \n",
    "df_survival1['OFFER_TOMORROW']=df_survival1['OFFER_TOMORROW'].astype('int')                     \n",
    "                      \n",
    "X_train=df_survival1[df_survival1['LISTING_ID'].isin(train_id)].drop(['diff_days','OFFER_TOMORROW','LISTING_ID'],axis=1)\n",
    "X_test=df_survival1[df_survival1['LISTING_ID'].isin(test_id)].drop(['diff_days','OFFER_TOMORROW','LISTING_ID'],axis=1) \n",
    "y_train=df_survival1[df_survival1['LISTING_ID'].isin(train_id)]['OFFER_TOMORROW']\n",
    "y_test=df_survival1[df_survival1['LISTING_ID'].isin(test_id)]['OFFER_TOMORROW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abcc=[]\n",
    "for i in range(len(df_survival1.columns)):\n",
    "    if 'COMPUTED' in df_survival1.columns[i]:\n",
    "        abcc.append(i)\n",
    "\n",
    "PCA_computed = PCA(n_components=0.99995)\n",
    "PCA_com = PCA_computed.fit(df_survival1.iloc[:,27:45])\n",
    "#principal_com_Df = pd.DataFrame(data = PCA_com\n",
    "             #, columns = ['COM_PC1', 'COM_PC2','COM_PC3','COM_PC4','COM_PC5','COM_PC6','COM_PC7','COM_PC8'])\n",
    "com_df=pd.DataFrame(PCA_computed.transform(df_survival1.iloc[:,27:45]))\n",
    "com_df.columns=['COM_PC1', 'COM_PC2','COM_PC3','COM_PC4','COM_PC5','COM_PC6','COM_PC7','COM_PC8']\n",
    "\n",
    "\n",
    "df_survival1=df_survival1.drop(df_survival.iloc[:,27:45], axis=1)\n",
    "df_survival1=df_survival1.join(com_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier()\n",
    "rf_model=rf.fit(X_train,y_train)\n",
    "rf_pred=rf.predict(X_test)\n",
    "rf_acc=accuracy_score(rf_pred,y_test)\n",
    "print('random forest accuracy for predicting offer_or_not is '+str(rf_acc))\n",
    "#print('random forest auc: '+str(roc_auc_score(rf_pred,y_test)))\n",
    "print('random forest average precision score: '+str(average_precision_score(rf_pred,y_test)))\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "rf_importance_df=pd.DataFrame({'feature':list(df_survival.drop(['diff_days','EVENT_UTC','LISTING_ID','OFFER_TOMORROW','OFFER_OR_NOT',\n",
    "                                                                 'LISTING_INITIAL_PUBLISH_TS','DISCOUNT','OFFER_OR_NOT','ZESTIMATE',\n",
    "                                                                 'PREVIOUSYEARLYPROPERTYTAXES','OFFER_TOMORROW'],\n",
    "                                                         axis=1).columns),'importance':importances})\n",
    "rf_importance_df_order=rf_importance_df[rf_importance_df['importance']>0].sort_values('importance',ascending=False)\n",
    "rf_importance_df_order[:20].plot.bar(x='feature')\n",
    "rf_proba=rf.predict_proba(X_test)[:,1]\n",
    "tt=X_test.copy()\n",
    "tt['PROBA']=rf_proba\n",
    "tt['LISTING_ID']=list(df_survival1[df_survival1['LISTING_ID'].isin(test_id)]['LISTING_ID'])\n",
    "tt['DIFF_DAYS']=list(df_survival1[df_survival1['LISTING_ID'].isin(test_id)]['diff_days'])\n",
    "tt=tt.groupby('LISTING_ID').apply(lambda t: t[t.PROBA==t.PROBA.max()]).drop_duplicates()\n",
    "tt=tt.drop('LISTING_ID',axis=1).reset_index().drop('level_1',axis=1)\n",
    "tt=tt.drop_duplicates('LISTING_ID',keep='last')\n",
    "print('mae for survival analysis for random forest: '+str(np.mean(abs(tt['DIFF_DAYS']-tt['DAY_ON_MARKET']))))\n",
    "print('RMSE for survival analysis for random forest: '+str(np.mean((tt['DIFF_DAYS'])**2-(tt['DAY_ON_MARKET'])**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=LogisticRegression()\n",
    "rf_model=rf.fit(X_train,y_train)\n",
    "rf_pred=rf.predict(X_test)\n",
    "rf_acc=accuracy_score(rf_pred,y_test)\n",
    "print('random forest accuracy for predicting offer_or_not is '+str(rf_acc))\n",
    "#print('random forest auc: '+str(roc_auc_score(rf_pred,y_test)))\n",
    "print('random forest average precision score: '+str(average_precision_score(rf_pred,y_test)))\n",
    "\n",
    "\n",
    "tt=X_test.copy()\n",
    "tt['PROBA']=rf_proba\n",
    "tt['LISTING_ID']=list(df_survival1[df_survival1['LISTING_ID'].isin(test_id)]['LISTING_ID'])\n",
    "tt['DIFF_DAYS']=list(df_survival1[df_survival1['LISTING_ID'].isin(test_id)]['diff_days'])\n",
    "tt=tt.groupby('LISTING_ID').apply(lambda t: t[t.PROBA==t.PROBA.max()]).drop_duplicates()\n",
    "tt=tt.drop('LISTING_ID',axis=1).reset_index().drop('level_1',axis=1)\n",
    "tt=tt.drop_duplicates('LISTING_ID',keep='last')\n",
    "print('mae for survival analysis for random forest: '+str(np.mean(abs(tt['DIFF_DAYS']-tt['DAY_ON_MARKET']))))\n",
    "print('RMSE for survival analysis for random forest: '+str((np.mean((tt['DIFF_DAYS'])**2-(tt['DAY_ON_MARKET'])**2)))**0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
